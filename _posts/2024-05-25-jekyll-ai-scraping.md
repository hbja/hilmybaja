---
layout: post
title: "Blocking AI bots with robots.txt in Jekyll"
date: 2024-05-25
categories:
- ai
- jekyll
og_image: jekyll-ai-scraping.png
---

Although I don't think this blog is popular enough
to be scraped by any of the AI companies,
I was curious about how to opt out of these scrapers.
The easiest way to block AI bots
from crawling a site
is through the robots.txt file.

This site uses the jekyll-sitemap gem
to generate the robots.txt file
with a sitemap url,
so the first step is to replicate
[the robots.txt generated by the gem](https://github.com/jekyll/jekyll-sitemap/blob/master/lib/robots.txt).
I had to add some YAML front matter at the top
to let Jekyll know to render the `.txt` file as markdown.

```markdown
---
layout: null
sitemap: false
---
Sitemap: {{ "sitemap.xml" | absolute_url }}
```

Now you can disallow any bot
by adding a rule like this one,
which blocks the ChatGPT bot:

```
User-agent: GPTBot
Disallow: /
```

[Neil Clarke has an excellent post](https://neil-clarke.com/block-the-bots-that-feed-ai-models-by-scraping-your-website/)
with a comprehensive list of AI bots to block.
You can also look at
[this site's robots.txt](https://github.com/nithinbekal/nithinbekal.github.io/blob/47b804179d111fcfe9a4914ccf6618263b0da3bd/robots.txt).
